{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRCtransformersUNI_CMLM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsg9c4b80ZxRF+b0hCbBkh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazimianec/TARIC/blob/master/TRCtransformersUNI_CMLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31bjoeeFzmID"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohMfpE86NGaA"
      },
      "source": [
        "url_TARIC_C2_descrptions = \"https://raw.githubusercontent.com/kazimianec/TARIC/master/DATA/TARIC_C2_descriptions.csv\"\r\n",
        "url_TARIC_C4_descrptions =\"https://raw.githubusercontent.com/kazimianec/TARIC/master/DATA/TARIC_C4_descriptions.csv\"\r\n",
        "url_TARIC_C6_descrptions =\"https://raw.githubusercontent.com/kazimianec/TARIC/master/DATA/TARIC_C6_descriptions.csv\"\r\n",
        "url_TARIC_C246_descrptions = \"https://raw.githubusercontent.com/kazimianec/TARIC/master/DATA/TARIC_C246_descriptions_CONCAT.csv\"\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhqP_RJ9_7wT"
      },
      "source": [
        "import pandas as pd \r\n",
        "import io \r\n",
        "  \r\n",
        "df_C2_descriptions = pd.read_csv(url_TARIC_C2_descrptions) \r\n",
        "df_C4_descriptions = pd.read_csv(url_TARIC_C4_descrptions)\r\n",
        "df_C6_descriptions = pd.read_csv(url_TARIC_C6_descrptions)\r\n",
        "df_C246_descriptions = pd.read_csv(url_TARIC_C246_descrptions)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbs9ZsjKhB-L",
        "outputId": "f06cb6f1-d5ba-4e4a-a44e-d2a8c7a56952"
      },
      "source": [
        "for col in df_C246_descriptions.columns: \r\n",
        "    print(col)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CODE_2\n",
            "CODE_4\n",
            "CODE_6\n",
            "goods_CODE_6\n",
            "Description_46\n",
            "Description_246\n",
            "Description_46_concat\n",
            "Description_246_concat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWRhD_7I_73_"
      },
      "source": [
        "#sentences = df['CLASS_Description'].tolist()\r\n",
        "\r\n",
        "sentences_C2 = df_C2_descriptions['Description_2'].tolist()\r\n",
        "sentences_C4 = df_C4_descriptions['Description_4'].tolist()\r\n",
        "sentences_C6 = df_C6_descriptions['Description_6'].tolist()\r\n",
        "\r\n",
        "sentences_C246 = df_C246_descriptions['Description_246'].tolist()\r\n",
        "sentences_C46 = df_C246_descriptions['Description_46'].tolist()\r\n",
        "\r\n",
        "sentences_C246_concat = df_C246_descriptions['Description_246_concat'].tolist()\r\n",
        "sentences_C46_concat = df_C246_descriptions['Description_46_concat'].tolist()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCoScJ--kCJQ"
      },
      "source": [
        "sentences = sentences_C246\r\n",
        "sentences = [element.lower() for element in sentences]\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX4N--sli603"
      },
      "source": [
        "**Test 0. \"Good descriptions\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZlYoqZlhB6N"
      },
      "source": [
        "**Test 1. English, all words are NOT in TARIC**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucvSDl1ihW33"
      },
      "source": [
        "**Test 2. Englsih, words are in \"EXCLUDING ...\", \"OTHER THAN....\" parts of TARIC descriptions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSwps7pSjRE_"
      },
      "source": [
        "**Test 3. Not obvious descriptions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgZ2fHRVuF3L"
      },
      "source": [
        "description = [\"Sterling Silver Turquoise Art Deco Earrings\"]\r\n",
        "description = [\"I Love Makeup - Nail Polish\"]\r\n",
        "description = [\"Astro Pneumatic 1716 Deluxe Air Blow Gun with 20-Inch Long Angled Nozzle and 1/2-Inch Removable Rubber Tip\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C55VEYqOoQXw"
      },
      "source": [
        "**UNIVESAL SENTNCE ENCODER CMLM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzTkaucchTip"
      },
      "source": [
        "import tensorflow_hub as hub\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "old8HeIhyr7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8a7f2f-4c8f-4620-e6c6-79a683568544"
      },
      "source": [
        "!pip install tensorflow_text\r\n",
        "import tensorflow_text"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/86/22ad798f94d564c3e423758b60ddd3689e83ad629b3f31ff2ae45a6e3eed/tensorflow_text-2.4.3-cp36-cp36m-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text) (0.11.0)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text) (2.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.36.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.32.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.3.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.8.0->tensorflow_text) (51.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.1.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBFGHVNtnHqo"
      },
      "source": [
        "#english_sentences = tf.constant([\"dog\", \"Puppies are nice.\", \"I enjoy taking long walks along the beach with my dog.\"])\r\n",
        "#TARIC_sentences = tf.constant(sentences)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra5Dji6WnkCS"
      },
      "source": [
        "preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Wp1YTupSaL"
      },
      "source": [
        "encoder = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/en-large/1\")\r\n",
        "#encoder = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/en-base/1\")\r\n",
        "\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFsLXKn9EqRh"
      },
      "source": [
        "embeddings_TARIC_long = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCcv_L50EQAC"
      },
      "source": [
        "# cycle is less efficient comparing to vectorised processing, but uses less memory\r\n",
        "# and vector version would be just:\r\n",
        "#embeddings_TARIC_long = encoder(preprocessor(TARIC_sentences))[\"default\"]\r\n",
        "\r\n",
        "for sentence_id in sentences:\r\n",
        "# take a care on square brackets. It expects a tensor, not just a string. So, reshaping sentence_id\r\n",
        "  embeddings_TARIC_id = encoder(preprocessor(tf.constant([sentence_id])))[\"default\"]\r\n",
        "  embeddings_TARIC_long.append(embeddings_TARIC_id)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WEg06lALXuF",
        "outputId": "c0266946-f0cb-458a-97ca-4c933a6a1dc1"
      },
      "source": [
        "embeddings_TARIC_long = tf.squeeze(embeddings_TARIC_long)\r\n",
        "print(embeddings_TARIC_long.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5209, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xiyy93bOpuMP"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjkfJ1UXomrO"
      },
      "source": [
        "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\r\n",
        "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\r\n",
        "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\r\n",
        "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\")\r\n",
        "#embed = hub.load (\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybI9PAnjqNL4"
      },
      "source": [
        "# = embed(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dInBPBKEo84-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "7f92346f-36df-4ca7-e002-08629e87ae53"
      },
      "source": [
        "\r\n",
        "\r\n",
        "description = [\"Sterling Silver Turquoise Art Deco Earrings\"]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "description = [\"Vyriškos kelnės\"]\r\n",
        "\r\n",
        "description = [\"I Love Makeup - Nail Polish\"] #yes!\r\n",
        "description = [\"Astro Pneumatic 1716 Deluxe Air Blow Gun with 20-Inch Long Angled Nozzle and 1/2-Inch Removable Rubber Tip\"] #no\r\n",
        "description = [\"Astro Pneumatic 1716 Deluxe Air Blow Gun with 20-Inch Long Angled Nozzle and 1/2-Inch Removable Rubber Tip\"]\r\n",
        "description = [\"Fosmon Apple iPhone 4 / iPhone 4G USB Sync Charge Data Cable with USB Auto Car Charger and USB Home Travel Charger\"] #SUPER matches S3\r\n",
        "description = [\"Astro Pneumatic 1716 Deluxe Air Blow Gun with 20-Inch Long Angled Nozzle and 1/2-Inch Removable Rubber Tip\"] # not\r\n",
        "\r\n",
        "\r\n",
        "description = [\"HTC HD7 Crowned Heart Phone Protector Cover Case\"] ## bullshit is both cases - bert and S3\r\n",
        "description = [\"Fosmon Apple iPhone 4 / iPhone 4G USB Sync Charge Data Cable with USB Auto Car Charger and USB Home Travel Charger\"] #SUPER matches S3 \r\n",
        "\r\n",
        "description = [\"Sterling Silver Turquoise Art Deco Earrings\"]\r\n",
        "\r\n",
        "\r\n",
        "description = [\"Fosmon Apple iPhone 4 / iPhone 4G USB Sync Charge Data Cable with USB Auto Car Charger and USB Home Travel Charger\"] #SUPER matches S3 \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "description = [\"Jolly Jumper Pashmama Nursing Cover - Tan \"]\r\n",
        "description = [\"HTC HD7 Crowned Heart Phone Protector Cover Case\"]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "description = [\"Jolly Jumper Pashmama Nursing Cover - Tan\"]\r\n",
        "description = [\"Astro Pneumatic 1716 Deluxe Air Blow Gun with 20-Inch Long Angled Nozzle and 1/2-Inch Removable Rubber Tip\"]\r\n",
        "\r\n",
        "description = [\"Fosmon Apple iPhone 4 / iPhone 4G USB Sync Charge Data Cable with USB Auto Car Charger and USB Home Travel Charger\"]\r\n",
        "\r\n",
        "description = [\"Meat beef\"]\r\n",
        "description = [\"I Love Makeup - Nail Polish\"] #yes!\r\n",
        "\r\n",
        "TARIC_description = tf.constant(description)\r\n",
        "embeddings_description = encoder(preprocessor(TARIC_description))[\"default\"]\r\n",
        "\r\n",
        "\r\n",
        "cosine=np.dot(embeddings_TARIC_long, np.transpose(embeddings_description))\r\n",
        "cosine=np.inner(embeddings_TARIC_long, embeddings_description)\r\n",
        "#print(cosine)\r\n",
        "ind_max = tf.constant(tf.argmax(cosine)).numpy()[0]\r\n",
        "top_ind = tf.math.top_k(np.transpose(cosine), k=5, sorted=True, name=None).indices.numpy()[0]\r\n",
        "top_value = tf.math.top_k(np.transpose(cosine), k=5, sorted=True, name=None).values.numpy()[0]\r\n",
        "print(ind_max, ind_max.shape)\r\n",
        "print(cosine[ind_max])\r\n",
        "print(sentences[ind_max])\r\n",
        "#print(top_value[0], sentences[top_ind[0]])\r\n",
        "#print(top_value[1], sentences[top_ind[1]])\r\n",
        "#print(top_value[2], sentences[top_ind[2]])\r\n",
        "#print(top_value[3], sentences[top_ind[3]])\r\n",
        "#rint(top_value[4], sentences[top_ind[4]])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1562] (1,)\n",
            "[[[541.61847]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a7460ab897f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;31m#print(top_value[0], sentences[top_ind[0]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#print(top_value[1], sentences[top_ind[1]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW7GD8UBydMZ",
        "outputId": "5a1e9c49-0cb9-42a5-e96d-99f657ecfa78"
      },
      "source": [
        "cosine.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}